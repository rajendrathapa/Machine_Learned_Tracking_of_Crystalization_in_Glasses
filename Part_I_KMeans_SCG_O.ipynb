{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28871014",
   "metadata": {},
   "source": [
    "Part I: \n",
    "- runs all loading of the .dump files\n",
    "- divides the loaded data into chunks: one chunk for each snapshot\n",
    "- calculates the computationally heavy calculation of disp, N_N, d_5NN etc\n",
    "- saves the dataframes with all required features into the features_csv folder\n",
    "\n",
    "NB: All clustering algorithm calculation will be done in Part II\n",
    "\n",
    "\n",
    "# Clustering Algorithm applied to atom classification\n",
    "\n",
    "- Clustering algorithm used to classify atoms as crystal-like and glass-like based on the features\n",
    "- Clustering applied to each snapshot\n",
    "- Program must be run from the directory that contains individual directory for each snapshot\n",
    "- Each directory must be named in a pre-defined fashion (0000ps, 0100ps, 0200ps,............., 2000ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddb7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3758b",
   "metadata": {},
   "source": [
    "- *.dump file contains the dump obtained from the lammps output (Has all the LAMMPS calculated quantities for each atom)\n",
    "- LAMMPS does not arrange the atoms in order of their indices like DL-POLY does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d643f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "def load_dump_files(file_path, label):\n",
    "    '''Inputs:\n",
    "        file_path=path to the directories where the dump files are located\n",
    "        label = ID for the atom to be pulled out from the LAMMPS dump file\n",
    "       Outputs:\n",
    "        dump_contents = contents of variable values form all the snapshots in chronological order\n",
    "        num_snaps = total number of snapshots present in the study       \n",
    "        box = list of the box size at each snapshot\n",
    "    '''\n",
    "    dump_contents, box = [],[]\n",
    "    files = sorted(glob.glob(file_path, recursive=True)) # sorts dump files in chronological order\n",
    "    num_snaps = 0\n",
    "    for filename in files:\n",
    "        num_snaps += 1\n",
    "        with open(filename, 'r',encoding='utf-8') as infile:\n",
    "            print(filename)\n",
    "            txt = infile.readlines()\n",
    "            # Skip first 9 lines that contains system information not coordinates\n",
    "            for line in txt[9:]:                        \n",
    "                if line.split()[1] == label: \n",
    "                    dump_contents.append(np.array(line.split()).astype(float) )\n",
    "            box.append(float(txt[5].split()[1]) - float(txt[5].split()[0]))\n",
    "    return dump_contents, num_snaps, box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ef7fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./0000ps/0ps.dump\n",
      "./0100ps/100ps.dump\n",
      "./0200ps/200ps.dump\n",
      "./0300ps/300ps.dump\n",
      "./0400ps/400ps.dump\n",
      "./0500ps/500ps.dump\n",
      "./0600ps/600ps.dump\n",
      "./0700ps/700ps.dump\n",
      "./0800ps/800ps.dump\n",
      "./0900ps/900ps.dump\n",
      "./1000ps/1000ps.dump\n",
      "./1100ps/1100ps.dump\n",
      "./1200ps/1200ps.dump\n",
      "./1300ps/1300ps.dump\n",
      "./1400ps/1400ps.dump\n",
      "./1500ps/1500ps.dump\n",
      "./1600ps/1600ps.dump\n",
      "./1700ps/1700ps.dump\n",
      "./1800ps/1800ps.dump\n"
     ]
    }
   ],
   "source": [
    "# label=\"3\" for O, \"2\" for Nb, \"1\" for Li\n",
    "# The description of crystallization based on the oxygen network and order is unique in the study of nucleation.\n",
    "dump_contents, num_snaps, box = load_dump_files(file_path = './*/**.dump', label=\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7218fc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of atoms: 121500 \n",
      "No. of snaps: 19\n"
     ]
    }
   ],
   "source": [
    "NAT=(int(len(dump_contents)/num_snaps))\n",
    "print(\"No. of atoms: %d \\nNo. of snaps: %d\"%(NAT, num_snaps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a673a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2308500 entries, 0 to 2308499\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   ID      float64\n",
      " 1   Atom    float64\n",
      " 2   x       float64\n",
      " 3   y       float64\n",
      " 4   z       float64\n",
      " 5   Q4      float64\n",
      " 6   Q6      float64\n",
      " 7   Q8      float64\n",
      " 8   Q10     float64\n",
      " 9   Nc_6    float64\n",
      " 10  Nc_8    float64\n",
      " 11  c_x     float64\n",
      " 12  c_y     float64\n",
      " 13  c_z     float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 246.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert the dump_contents list into a dataframe and name the columns\n",
    "df = pd.DataFrame(dump_contents)\n",
    "\n",
    "df.columns=['ID',\"Atom\",\"x\",\"y\",\"z\",\"Q4\",\"Q6\",\"Q8\",\"Q10\",\"Nc_6\",\"Nc_8\",\"c_x\",\"c_y\",\"c_z\"]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a57a4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2308500 entries, 0 to 2308499\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   ID      int64  \n",
      " 1   Atom    int64  \n",
      " 2   x       float64\n",
      " 3   y       float64\n",
      " 4   z       float64\n",
      " 5   Q4      float64\n",
      " 6   Q6      float64\n",
      " 7   Q8      float64\n",
      " 8   Q10     float64\n",
      " 9   Nc_6    int64  \n",
      " 10  Nc_8    int64  \n",
      " 11  c_x     float64\n",
      " 12  c_y     float64\n",
      " 13  c_z     float64\n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 246.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Change the data type of the columns appropriately\n",
    "df = df.astype({\"ID\": int, \"Atom\": int, \"Nc_6\":int, \"Nc_8\":int})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a4e21",
   "metadata": {},
   "source": [
    "### Feature Engineering begins here\n",
    "\n",
    "- Create a calculated column the find the distance from the center\n",
    "- Remember the system has center at (0,0,0)\n",
    "- Keep only columns that will be needed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b4ad96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Nc_6</th>\n",
       "      <th>dist_from_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.308500e+06</td>\n",
       "      <td>2.308500e+06</td>\n",
       "      <td>2.308500e+06</td>\n",
       "      <td>2.308500e+06</td>\n",
       "      <td>2.308500e+06</td>\n",
       "      <td>2.308500e+06</td>\n",
       "      <td>2.308500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.417505e+05</td>\n",
       "      <td>-1.698368e-02</td>\n",
       "      <td>3.999293e-02</td>\n",
       "      <td>-3.700484e-02</td>\n",
       "      <td>2.759255e-01</td>\n",
       "      <td>2.787663e+00</td>\n",
       "      <td>6.762949e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.507404e+04</td>\n",
       "      <td>4.067301e+01</td>\n",
       "      <td>4.065108e+01</td>\n",
       "      <td>4.067496e+01</td>\n",
       "      <td>4.841351e-02</td>\n",
       "      <td>3.182917e+00</td>\n",
       "      <td>1.968527e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.100100e+04</td>\n",
       "      <td>-7.077720e+01</td>\n",
       "      <td>-7.077650e+01</td>\n",
       "      <td>-7.077900e+01</td>\n",
       "      <td>6.639430e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.410858e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.113758e+05</td>\n",
       "      <td>-3.517903e+01</td>\n",
       "      <td>-3.508690e+01</td>\n",
       "      <td>-3.520945e+01</td>\n",
       "      <td>2.428790e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.492135e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.417505e+05</td>\n",
       "      <td>-6.198715e-02</td>\n",
       "      <td>6.882165e-02</td>\n",
       "      <td>-7.817165e-02</td>\n",
       "      <td>2.756860e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>6.935329e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.721252e+05</td>\n",
       "      <td>3.516230e+01</td>\n",
       "      <td>3.517630e+01</td>\n",
       "      <td>3.513270e+01</td>\n",
       "      <td>3.085580e-01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.172729e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.025000e+05</td>\n",
       "      <td>7.077780e+01</td>\n",
       "      <td>7.077880e+01</td>\n",
       "      <td>7.077750e+01</td>\n",
       "      <td>5.171810e-01</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>1.216688e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID             x             y             z            Q6  \\\n",
       "count  2.308500e+06  2.308500e+06  2.308500e+06  2.308500e+06  2.308500e+06   \n",
       "mean   1.417505e+05 -1.698368e-02  3.999293e-02 -3.700484e-02  2.759255e-01   \n",
       "std    3.507404e+04  4.067301e+01  4.065108e+01  4.067496e+01  4.841351e-02   \n",
       "min    8.100100e+04 -7.077720e+01 -7.077650e+01 -7.077900e+01  6.639430e-02   \n",
       "25%    1.113758e+05 -3.517903e+01 -3.508690e+01 -3.520945e+01  2.428790e-01   \n",
       "50%    1.417505e+05 -6.198715e-02  6.882165e-02 -7.817165e-02  2.756860e-01   \n",
       "75%    1.721252e+05  3.516230e+01  3.517630e+01  3.513270e+01  3.085580e-01   \n",
       "max    2.025000e+05  7.077780e+01  7.077880e+01  7.077750e+01  5.171810e-01   \n",
       "\n",
       "               Nc_6   dist_from_c  \n",
       "count  2.308500e+06  2.308500e+06  \n",
       "mean   2.787663e+00  6.762949e+01  \n",
       "std    3.182917e+00  1.968527e+01  \n",
       "min    0.000000e+00  3.410858e-01  \n",
       "25%    1.000000e+00  5.492135e+01  \n",
       "50%    2.000000e+00  6.935329e+01  \n",
       "75%    3.000000e+00  8.172729e+01  \n",
       "max    3.300000e+01  1.216688e+02  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember the center of our system is (0,0,0). If otherwise, you need to change the equation for df['dist_from_c']\n",
    "df['dist_from_c'] = np.sqrt((df['x']**2+df['y']**2+df['z']**2))\n",
    "df = df[['ID','x','y','z','Q6','Nc_6','dist_from_c']]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d827770",
   "metadata": {},
   "source": [
    "__Looks exactly the way we want our data to be!__\n",
    "\n",
    "- To perform clustering on each snapshot, we need to divide the dataframe into chunks for each snapshot\n",
    "- Each chunk must have NAT atoms\n",
    "- Each chunk needs to be sorted because the LAMMPS dump does not sort by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e43ed18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Nc_6</th>\n",
       "      <th>dist_from_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>141750.500000</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>0.055560</td>\n",
       "      <td>-0.058775</td>\n",
       "      <td>0.274029</td>\n",
       "      <td>2.984041</td>\n",
       "      <td>64.324448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35074.173191</td>\n",
       "      <td>38.681949</td>\n",
       "      <td>38.660557</td>\n",
       "      <td>38.666512</td>\n",
       "      <td>0.045759</td>\n",
       "      <td>3.371026</td>\n",
       "      <td>18.664644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>81001.000000</td>\n",
       "      <td>-67.020400</td>\n",
       "      <td>-67.016700</td>\n",
       "      <td>-67.021600</td>\n",
       "      <td>0.072866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>111375.750000</td>\n",
       "      <td>-33.525025</td>\n",
       "      <td>-33.378525</td>\n",
       "      <td>-33.508600</td>\n",
       "      <td>0.243665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.284070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>141750.500000</td>\n",
       "      <td>-0.048452</td>\n",
       "      <td>0.056104</td>\n",
       "      <td>-0.131143</td>\n",
       "      <td>0.275448</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>65.957467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>172125.250000</td>\n",
       "      <td>33.465225</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>33.368825</td>\n",
       "      <td>0.305249</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>77.697023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>202500.000000</td>\n",
       "      <td>67.021600</td>\n",
       "      <td>67.021900</td>\n",
       "      <td>67.021500</td>\n",
       "      <td>0.469364</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>115.703800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID              x              y              z  \\\n",
       "count  121500.000000  121500.000000  121500.000000  121500.000000   \n",
       "mean   141750.500000      -0.005931       0.055560      -0.058775   \n",
       "std     35074.173191      38.681949      38.660557      38.666512   \n",
       "min     81001.000000     -67.020400     -67.016700     -67.021600   \n",
       "25%    111375.750000     -33.525025     -33.378525     -33.508600   \n",
       "50%    141750.500000      -0.048452       0.056104      -0.131143   \n",
       "75%    172125.250000      33.465225      33.500000      33.368825   \n",
       "max    202500.000000      67.021600      67.021900      67.021500   \n",
       "\n",
       "                  Q6           Nc_6    dist_from_c  \n",
       "count  121500.000000  121500.000000  121500.000000  \n",
       "mean        0.274029       2.984041      64.324448  \n",
       "std         0.045759       3.371026      18.664644  \n",
       "min         0.072866       0.000000       0.351533  \n",
       "25%         0.243665       1.000000      52.284070  \n",
       "50%         0.275448       2.000000      65.957467  \n",
       "75%         0.305249       4.000000      77.697023  \n",
       "max         0.469364      30.000000     115.703800  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataframes = [df[i:i+NAT] for i in range(0, len(df), NAT)]\n",
    "sorted_chunks = [chunk.sort_values(by='ID') for chunk in split_dataframes]\n",
    "\n",
    "# If you want to see what the chunks look like, uncomment the lines below\n",
    "# for i, split_df in enumerate(sorted_chunks):\n",
    "#     print(f\"DataFrame {i + 1}:\")\n",
    "#     print(split_df)\n",
    "#     print()\n",
    "\n",
    "# Use the describe method to check the details of one of the chunks\n",
    "# count row must have values equal to NAT\n",
    "sorted_chunks[0].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b3b0e",
   "metadata": {},
   "source": [
    "## One more feature (Displacement)\n",
    "\n",
    "\n",
    "### __How do we calculate the displacement feature?__   \n",
    "- For each snapshot, calculate the disp for each atom at four different 5ps snaps just before or after the snap\n",
    "- For e.g, the disp for 200ps is calculated as the average of the disp at 195 ps, 190ps, 185ps, 180ps\n",
    "- disp at 195: dist(r_195ps, r_190ps)\n",
    "- We need to pull out the coordinates from the HISTORY file to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af7d8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_distance(atom, nbd, box):\n",
    "    '''Inputs:\n",
    "        atom = coordinate of a single reference atom\n",
    "        nbd = array of coordinates of multiple atoms\n",
    "        box = length of the box\n",
    "       Outputs:\n",
    "        dis = distance between atom and nbd\n",
    "        len(dis) == len(nbd)\n",
    "    '''\n",
    "    delta = np.abs(atom-nbd)\n",
    "    delta = np.where(delta> 0.5*box, delta-box, delta)\n",
    "    dis = np.sqrt((delta**2).sum(axis=-1))\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d3c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  29%|██▊       | 41893535/145801442 [01:13<02:26, 707856.70it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "search_string = \"O2\"\n",
    "found = False\n",
    "\n",
    "coords_A0=[]\n",
    "with open(\"../SCG/HISTORY\", \"r\") as file:\n",
    "    total_lines = sum(1 for _ in file)\n",
    "    file.seek(0)  # Reset the file pointer to the beginning\n",
    "    progress_bar = tqdm(total=total_lines, desc=\"Processing\")\n",
    "\n",
    "    for line in file:\n",
    "        progress_bar.update(1)  # Update the progress bar\n",
    "        if search_string in line:\n",
    "            found = True\n",
    "        elif found:\n",
    "            # Print or store the following line\n",
    "            coords_A0.append(np.asarray(line.split()).astype(float))  # or do something else with the line\n",
    "            found = False\n",
    "\n",
    "    progress_bar.close()  # Close the prog\n",
    "\n",
    "coords_A0 = np.asarray(coords_A0).astype(float)\n",
    "print(np.shape(coords_A0))\n",
    "print(f\"Number of snaps in the HISTORY file is {int(len(coords_A0)/NAT)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6cf9ba",
   "metadata": {},
   "source": [
    "- 100ps.lammps was taken from the 20st set of coordinates from the A0/HISTORY file. \n",
    "- choose the neighboring sets of coordianates to calculate the displacement. \n",
    "- 100ps - 20\n",
    "- 200ps - 40\n",
    "- 300ps - 60\n",
    "- 1300ps - 260\n",
    "\n",
    "- if you want to pull out the 20set of coordinates you will need the slice coords_A0[19NAT:20NAT, :]\n",
    "\n",
    "- use coords_A0 for calculating disp for 100ps, 200ps, ............., 1300ps.\n",
    " \n",
    "- skipping the calculation on 0ps ( start the loop at 1, i.e. chunks for 100ps)\n",
    "\n",
    "- choose snaps_A0 wisely: Remember how many snaps were taken from A0/HISTORY? Our last snap from A0/HISTORY was 1300ps. So our loop must run for 13 iterations (100ps, 200ps, ............, 1300ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f052b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0036816824729775 2.0143528626194147 1.9931082751026103 1.9949814820022824\n",
      "1.9773563895984476 1.974114796490307 1.9849747398825 1.9635903908315988\n",
      "1.9782634158250947 1.9955912296172176 1.9859227171852463 1.984451497372339\n",
      "1.9994675265227047 1.9687438511273974 1.9990692355308286 1.981581737301425\n",
      "1.9667461780684654 1.9685253008897539 1.9558270512379028 1.9783501303317153\n",
      "1.9724035064600183 1.972351733702344 1.9568223270434228 1.97436715525356\n",
      "1.9747651709848288 1.9893034860453471 2.0001151621651245 1.9774670773690368\n",
      "1.9328519302887153 1.9305142712394483 1.929688129031636 1.940050139492475\n",
      "1.9269573440655317 1.9204502496563314 1.9399877975636641 1.9671429801930687\n",
      "1.919351991596799 1.9179871330522416 1.926209322418265 1.91215046380705\n",
      "1.909214728579194 1.8929509949147931 1.8913478464376348 1.9150196027623065\n",
      "1.8908408206932394 1.8915065723442266 1.9046833614643277 1.8885272320362168\n",
      "1.8534181902089788 1.8651392451098292 1.8726647066244104 1.8758991500062387\n",
      "1.8588723767419992 1.8603122406350547 1.8572895247392507 1.870914934073932\n",
      "1.8276094706506567 1.8286916510611033 1.8191148401755053 1.8314999024161989\n",
      "1.7837254308853125 1.7736912175545874 1.7923850297201982 1.7886200179365965\n",
      "1.7615448304247607 1.7626478386679363 1.7796273113664107 1.7732636363472656\n",
      "1.718582128695442 1.7212104080738304 1.700664004422801 1.7103102512658486\n"
     ]
    }
   ],
   "source": [
    "for ind in range(1, num_snaps):\n",
    "    # Locate the starting index for the snapshot 100ps (if ind=1), 200ps(if ind=2),etc.\n",
    "    # 20th set will have slice indices [19*NAT, 20*NAT]\n",
    "    s1 = int((ind*100)/5.-1)*NAT\n",
    "    \n",
    "    snap_ = coords_A0[s1: s1+NAT, :]\n",
    "    nbd_1 = coords_A0[s1-NAT: s1, :]\n",
    "    nbd_2 = coords_A0[s1-2*NAT: s1-NAT, :]\n",
    "    nbd_3 = coords_A0[s1-3*NAT: s1-2*NAT, :]\n",
    "    nbd_4 = coords_A0[s1-4*NAT: s1-3*NAT, :]\n",
    "\n",
    "    d1 = periodic_distance(snap_, nbd_1, box[ind])\n",
    "    d2 = periodic_distance(nbd_1, nbd_2, box[ind])\n",
    "    d3 = periodic_distance(nbd_2, nbd_3, box[ind])\n",
    "    d4 = periodic_distance(nbd_3, nbd_4, box[ind])\n",
    "    print(np.mean(d1), np.mean(d2), np.mean(d3), np.mean(d4))\n",
    "\n",
    "    dist = 0.25*(d1+d2+d3+d4)\n",
    "    sorted_chunks[ind]['disp'] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5ad4f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Nc_6</th>\n",
       "      <th>dist_from_c</th>\n",
       "      <th>disp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>121500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>141750.500000</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.062373</td>\n",
       "      <td>-0.014049</td>\n",
       "      <td>0.276670</td>\n",
       "      <td>2.931457</td>\n",
       "      <td>67.745669</td>\n",
       "      <td>1.866780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35074.173191</td>\n",
       "      <td>40.741798</td>\n",
       "      <td>40.722511</td>\n",
       "      <td>40.747027</td>\n",
       "      <td>0.048886</td>\n",
       "      <td>3.393478</td>\n",
       "      <td>19.723787</td>\n",
       "      <td>0.727076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>81001.000000</td>\n",
       "      <td>-70.675200</td>\n",
       "      <td>-70.674700</td>\n",
       "      <td>-70.672400</td>\n",
       "      <td>0.069728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.173554</td>\n",
       "      <td>0.199630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>111375.750000</td>\n",
       "      <td>-35.271100</td>\n",
       "      <td>-35.148850</td>\n",
       "      <td>-35.222100</td>\n",
       "      <td>0.243421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.039559</td>\n",
       "      <td>1.379479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>141750.500000</td>\n",
       "      <td>-0.013427</td>\n",
       "      <td>0.101887</td>\n",
       "      <td>-0.047503</td>\n",
       "      <td>0.276251</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>69.510731</td>\n",
       "      <td>1.842115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>172125.250000</td>\n",
       "      <td>35.231925</td>\n",
       "      <td>35.271700</td>\n",
       "      <td>35.207625</td>\n",
       "      <td>0.309573</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>81.868510</td>\n",
       "      <td>2.330937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>202500.000000</td>\n",
       "      <td>70.675700</td>\n",
       "      <td>70.674400</td>\n",
       "      <td>70.676300</td>\n",
       "      <td>0.517181</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>120.169206</td>\n",
       "      <td>5.756961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID              x              y              z  \\\n",
       "count  121500.000000  121500.000000  121500.000000  121500.000000   \n",
       "mean   141750.500000       0.002138       0.062373      -0.014049   \n",
       "std     35074.173191      40.741798      40.722511      40.747027   \n",
       "min     81001.000000     -70.675200     -70.674700     -70.672400   \n",
       "25%    111375.750000     -35.271100     -35.148850     -35.222100   \n",
       "50%    141750.500000      -0.013427       0.101887      -0.047503   \n",
       "75%    172125.250000      35.231925      35.271700      35.207625   \n",
       "max    202500.000000      70.675700      70.674400      70.676300   \n",
       "\n",
       "                  Q6           Nc_6    dist_from_c           disp  \n",
       "count  121500.000000  121500.000000  121500.000000  121500.000000  \n",
       "mean        0.276670       2.931457      67.745669       1.866780  \n",
       "std         0.048886       3.393478      19.723787       0.727076  \n",
       "min         0.069728       0.000000       1.173554       0.199630  \n",
       "25%         0.243421       1.000000      55.039559       1.379479  \n",
       "50%         0.276251       2.000000      69.510731       1.842115  \n",
       "75%         0.309573       3.000000      81.868510       2.330937  \n",
       "max         0.517181      30.000000     120.169206       5.756961  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_chunks[13].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f6297",
   "metadata": {},
   "source": [
    "__Great! We now have two new features added to our data__\n",
    "- Let us do the same for the A1/HISTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a873a-fb58-4530-90d1-a6f42b192cc2",
   "metadata": {},
   "source": [
    "found = False\n",
    "\n",
    "coords_A1=[]\n",
    "with open(\"../A1_HISTORY\", \"r\") as file:\n",
    "    total_lines = sum(1 for _ in file)\n",
    "    file.seek(0)  # Reset the file pointer to the beginning\n",
    "    progress_bar = tqdm(total=total_lines, desc=\"Processing\")\n",
    "    for line in file:\n",
    "        progress_bar.update(1)  # Update the progress bar\n",
    "        if search_string in line:\n",
    "            found = True\n",
    "        elif found:\n",
    "            coords_A1.append(np.asarray(line.split()).astype(float))  # or do something else with the line\n",
    "            found = False\n",
    "    progress_bar.close()  \n",
    "\n",
    "coords_A1 = np.asarray(coords_A1).astype(float)\n",
    "print(np.shape(coords_A1))\n",
    "print(f\"Number of snaps in the HISTORY file is {int(len(coords_A1)/NAT)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aff565",
   "metadata": {},
   "source": [
    "- 1400ps.lammps was taken from the 10th set of coordinates from the A1/HISTORY file. \n",
    "\n",
    "\n",
    "Let us use coords_A1 for calculating disp for 1400ps, 1500ps, ............., 2700ps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a9759-bb41-4952-a57b-2531af32ee88",
   "metadata": {},
   "source": [
    "snaps_A1 = 14\n",
    "for ind in range(1,snaps_A1+1):\n",
    "    s1 = int((ind*100)/5.-11)*NAT\n",
    "\n",
    "    snap_ = coords_A1[s1: s1+NAT, :]\n",
    "    nbd_1 = coords_A1[s1-NAT: s1, :]\n",
    "    nbd_2 = coords_A1[s1-2*NAT: s1-NAT, :]\n",
    "    nbd_3 = coords_A1[s1-3*NAT: s1-2*NAT, :]\n",
    "    nbd_4 = coords_A1[s1-4*NAT: s1-3*NAT, :]\n",
    "    \n",
    "    d1 = periodic_distance(snap_, nbd_1, box[ind])\n",
    "    d2 = periodic_distance(nbd_1, nbd_2, box[ind])\n",
    "    d3 = periodic_distance(nbd_2, nbd_3, box[ind])\n",
    "    d4 = periodic_distance(nbd_3, nbd_4, box[ind])\n",
    "    print(np.mean(d1), np.mean(d2), np.mean(d3), np.mean(d4))\n",
    "\n",
    "\n",
    "    dist = 0.25*(d1+d2+d3+d4)\n",
    "    sorted_chunks[ind+snaps_A0]['disp'] = dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240859b8",
   "metadata": {},
   "source": [
    "sorted_chunks[26].describe()    # This is the last snapshot done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd4410",
   "metadata": {},
   "source": [
    "- Great the disp features has been added to 100ps, 200ps, .............., 1700ps\n",
    "## More features (d_5NN, N_N)\n",
    "\n",
    "\n",
    "### __How do we calculate these features?__   \n",
    "- __d_5NN__: average distance of 5 nearest neighbors with Nc > 10 \n",
    "- __N_N__: number of atoms with 5A that have Nc > 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74c846",
   "metadata": {},
   "source": [
    "__Non parallel version of the code to calculate d_5NN and N_N__\n",
    "\n",
    "This code is highly inefficient as you might guess because it runs only on a single processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553efc7d",
   "metadata": {},
   "source": [
    "for ind in range(1,num_snaps):\n",
    "    '''num_neigh_list = list of number of neighbors within 5A with Nc > 10\n",
    "       avg_neigh_dist = average distance of 5 nearest neighbors with Nc > 10\n",
    "    '''\n",
    "    num_neigh_list, avg_neigh_dist = [], []\n",
    "    df_snap=sorted_chunks[ind]\n",
    "    print(f\"Working on {ind*100} ps.\")\n",
    "    prog_bar = pyprind.ProgBar(len(df_snap))\n",
    "    for j in range(len(df_snap)):\n",
    "        filtered_particles = df_snap[df_snap['Nc_6'] > 10]\n",
    "        particle_row = df_snap.iloc[j]\n",
    "        coordinates = [particle_row['x'], particle_row['y'], particle_row['z']]\n",
    "        distances = periodic_distance(coordinates, filtered_particles[['x','y','z']], box[ind])\n",
    "        sorted_distances = np.sort(distances)\n",
    "        # List of 5 nearest neighbors with Nc > 10\n",
    "        # If the reference atom itself has Nc > 10, the min value of distance will be 0 and that must be removed\n",
    "        nbd_5 = np.mean(sorted_distances[1:6]) if sorted_distances[0] == 0\\\n",
    "                else np.mean(sorted_distances[:5])\n",
    "        avg_neigh_dist.append(nbd_5)\n",
    "        \n",
    "        num_neigh = (len([x for x in distances if x < 5.0]) -1) if min(distances) == 0\\\n",
    "                    else len([x for x in distances if x < 5.0])    \n",
    "        num_neigh_list.append(num_neigh)\n",
    "        prog_bar.update()\n",
    "# Add the list as a column to the dataframe chunk\n",
    "    sorted_chunks[ind]['d_5NN'] = avg_neigh_dist\n",
    "    sorted_chunks[ind]['N_N'] = num_neigh_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3f1aa",
   "metadata": {},
   "source": [
    "__d_5NN and N_N calculator using multiprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc4dcb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores available:  128\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(\"Number of CPU cores available: \",multiprocessing.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pyprind\n",
    "\n",
    "def process_snapshot(args):\n",
    "    df_snap, box = args\n",
    "    num_neigh_list, avg_neigh_dist = [], []\n",
    "    prog_bar = pyprind.ProgBar(len(df_snap))\n",
    "    for j in range(len(df_snap)):\n",
    "        filtered_particles = df_snap[df_snap['Nc_6'] > 10]\n",
    "        particle_row = df_snap.iloc[j]\n",
    "        coordinates = [particle_row['x'], particle_row['y'], particle_row['z']]\n",
    "        distances = periodic_distance(coordinates, filtered_particles[['x','y','z']], box)\n",
    "        sorted_distances = np.sort(distances)\n",
    "        nbd_5 = np.mean(sorted_distances[1:6]) if sorted_distances[0] == 0 else np.mean(sorted_distances[:5])\n",
    "        avg_neigh_dist.append(nbd_5)\n",
    "        num_neigh = (len([x for x in distances if x < 5.0]) - 1) if min(distances) == 0 else len([x for x in distances if x < 5.0])\n",
    "        num_neigh_list.append(num_neigh)\n",
    "        prog_bar.update()\n",
    "    return num_neigh_list, avg_neigh_dist\n",
    "\n",
    "def process_snapshots(sorted_chunks, box):\n",
    "    num_snaps = len(sorted_chunks)\n",
    "    # creates a multiprocessing pool object,\n",
    "    # which allows you to execute functions concurrently across multiple CPUs.\n",
    "    pool = multiprocessing.Pool()\n",
    "    results = pool.map(process_snapshot, [(df_snap, box[ind]) for ind, df_snap in enumerate(sorted_chunks)])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "# sorted_chunks is a list of dataframes containing snapshots\n",
    "# box is a list of box sizes corresponding to each snapshot\n",
    "results = process_snapshots(sorted_chunks, box)\n",
    "\n",
    "# Add the results back to the dataframe chunks\n",
    "for ind, (num_neigh_list, avg_neigh_dist) in enumerate(results):\n",
    "    sorted_chunks[ind]['d_5NN'] = avg_neigh_dist\n",
    "    sorted_chunks[ind]['N_N'] = num_neigh_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create a directory to store CSV files\n",
    "output_directory = \"features_csv\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop through the DataFrames and save them as CSV files\n",
    "for ind in range(1, num_snaps):\n",
    "    # Define the file name (you can customize this)\n",
    "    file_name = os.path.join(output_directory, f\"{ind*100}.csv\")\n",
    "    \n",
    "    # Save the DataFrame as a CSV file\n",
    "    sorted_chunks[ind].to_csv(file_name, index=False)\n",
    "\n",
    "print(\"CSV files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe24aba",
   "metadata": {},
   "source": [
    "__Let us look at how our variables are correlated__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1042b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NN_disp_corr, NN_Nc_corr, NN_dist_corr = [],[],[]\n",
    "for ind in range(1,num_snaps):\n",
    "    data = sorted_chunks[ind][['Q6','Nc_6','disp','N_N','dist_from_c']]\n",
    "    correlation_matrix = data.corr()\n",
    "    NN_dist_corr.append(correlation_matrix['N_N'].iloc[4])\n",
    "    NN_disp_corr.append(correlation_matrix['N_N'].iloc[2])\n",
    "    NN_Nc_corr.append(correlation_matrix['N_N'].iloc[1])\n",
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(NN_disp_corr, label=\"NN-disp\")\n",
    "plt.plot(NN_dist_corr, label=\"NN-dist\")\n",
    "# plt.plot(NN_Nc_corr, label=\"NN-Nc\")\n",
    "plt.legend()\n",
    "# plt.savefig(\"conf_mat.png\",dpi=500,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the correlation matrix in the last snapshot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.savefig(\"conf_mat.png\",dpi=500,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2dc65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528350f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
